{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48db003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required for feature engineering: pandas, numpy, and matplotlib\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in cleaned data for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Budget\n",
    "\n",
    "# ~8% missing or zero values\n",
    "# highly right-skewed (skew > 2.7)\n",
    "# median imputation preferred\n",
    "\n",
    "# drop duplicate\n",
    "merged_df.drop('tmdb_budget', axis=1, inplace=True)\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'budget': 'Budget'}, inplace=True)\n",
    "\n",
    "# replace 0s with NaN\n",
    "merged_df['Budget'] = merged_df['Budget'].replace(0, np.nan)\n",
    "\n",
    "# impute with median\n",
    "median_budget = merged_df['Budget'].median(skipna=True)\n",
    "merged_df['Budget'] = merged_df['Budget'].fillna(median_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5af99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Runtime\n",
    "\n",
    "# ~8% missing or zero values\n",
    "# highly right-skewed (skew > 3)\n",
    "# median imputation preferred\n",
    "\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'runtime': 'Runtime'})\n",
    "\n",
    "# replace 0s with NaN\n",
    "merged_df['Runtime'] = merged_df['Runtime'].replace(0, np.nan)\n",
    "\n",
    "# impute with median\n",
    "median_runtime = merged_df['Runtime'].median(skipna=True)\n",
    "merged_df['Runtime'] = merged_df['Runtime'].fillna(median_runtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Original Language\n",
    "\n",
    "# ~8% missing values\n",
    "# abbreviated values (e.g., 'en', 'fr') → mapped to full names\n",
    "# impute missing with 'Not available'\n",
    "\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'original_language': 'Original_Language'})\n",
    "\n",
    "# impute missing\n",
    "merged_df['Original_Language'] = merged_df['Original_Language'].fillna('Not available')\n",
    "\n",
    "# map abbreviated codes to full language names\n",
    "language_map = {\n",
    "    'Not available': 'Not available',\n",
    "    'en': 'English',\n",
    "    'zh': 'Chinese',\n",
    "    'sv': 'Swedish',\n",
    "    'es': 'Spanish',\n",
    "    'de': 'German',\n",
    "    'fr': 'French',\n",
    "    'xx': 'Not available',\n",
    "    'it': 'Italian',\n",
    "    'ka': 'Georgian',\n",
    "    'cs': 'Czech',\n",
    "    'fa': 'Persian',\n",
    "    'ro': 'Romanian',\n",
    "    'ja': 'Japanese',\n",
    "    'ar': 'Arabic',\n",
    "    'id': 'Indonesian',\n",
    "    'hu': 'Hungarian',\n",
    "    'tl': 'Tagalog',\n",
    "    'pl': 'Polish',\n",
    "    'sw': 'Swahili',\n",
    "    'no': 'Norwegian',\n",
    "    'pt': 'Portuguese',\n",
    "    'he': 'Hebrew',\n",
    "    'vi': 'Vietnamese',\n",
    "    'hi': 'Hindi',\n",
    "    'ru': 'Russian',\n",
    "    'af': 'Afrikaans',\n",
    "    'cn': 'Not available',\n",
    "    'ko': 'Korean',\n",
    "    'tr': 'Turkish',\n",
    "    'az': 'Azerbaijani',\n",
    "    'uk': 'Ukrainian',\n",
    "    'ga': 'Irish',\n",
    "    'as': 'Assamese',\n",
    "    'lv': 'Latvian',\n",
    "    'th': 'Thai',\n",
    "    'el': 'Greek',\n",
    "    'da': 'Danish',\n",
    "    'nl': 'Dutch',\n",
    "    'st': 'Southern Sotho',\n",
    "    'ky': 'Kyrgyz',\n",
    "    'fi': 'Finnish',\n",
    "    'is': 'Icelandic',\n",
    "    'ak': 'Akan',\n",
    "    'bn': 'Bengali',\n",
    "    'ml': 'Malayalam',\n",
    "    'hy': 'Armenian',\n",
    "    'am': 'Amharic',\n",
    "    'dz': 'Dzongkha',\n",
    "    'si': 'Sinhala',\n",
    "    'ln': 'Lingala',\n",
    "    'ur': 'Urdu',\n",
    "    'mn': 'Mongolian',\n",
    "    'la': 'Latin',\n",
    "    'te': 'Telugu',\n",
    "    'bs': 'Bosnian',\n",
    "    'bg': 'Bulgarian',\n",
    "    'ca': 'Catalan',\n",
    "    'kk': 'Kazakh',\n",
    "    'ne': 'Nepali',\n",
    "    'lt': 'Lithuanian',\n",
    "    'ta': 'Tamil',\n",
    "    'ms': 'Malay',\n",
    "    'wo': 'Wolof',\n",
    "    'eu': 'Basque',\n",
    "    'pa': 'Punjabi',\n",
    "    'mr': 'Marathi',\n",
    "    'hr': 'Croatian',\n",
    "    'mk': 'Macedonian',\n",
    "    'sq': 'Albanian',\n",
    "    'sr': 'Serbian'\n",
    "}\n",
    "\n",
    "merged_df['Original_Language'] = merged_df['Original_Language'].map(language_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf42485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Revenue\n",
    "\n",
    "# ~8% missing or zero values\n",
    "# highly right-skewed (skew > 4.0)\n",
    "# median imputation preferred\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_revenue': 'Revenue'}, inplace=True)\n",
    "\n",
    "# replace 0s with NaN\n",
    "merged_df['Revenue'] = merged_df['Revenue'].replace(0, np.nan)\n",
    "\n",
    "# impute with median\n",
    "median_revenue = merged_df['Revenue'].median(skipna=True)\n",
    "merged_df['Revenue'] = merged_df['Revenue'].fillna(median_revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41427074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Release_Date\n",
    "\n",
    "# ~8% missing values\n",
    "# categorical field → fill with placeholder string\n",
    "\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'release_date': 'Release_Date'})\n",
    "\n",
    "# impute with 'Not available'\n",
    "merged_df['Release_Date'] = merged_df['Release_Date'].fillna('Not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Popularity\n",
    "\n",
    "# ~8% missing values\n",
    "# heavy right skew (~17) → impute with median\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_popularity': 'Popularity'}, inplace=True)\n",
    "\n",
    "# replace 0s with NaN\n",
    "merged_df['Popularity'] = merged_df['Popularity'].replace(0, np.nan)\n",
    "\n",
    "# median imputation\n",
    "median_popularity = merged_df['Popularity'].median(skipna=True)\n",
    "merged_df['Popularity'] = merged_df['Popularity'].fillna(median_popularity)\n",
    "\n",
    "# inspect range\n",
    "print(f\"Minimum value: {merged_df['Popularity'].min()}\")\n",
    "print(f\"Maximum value: {merged_df['Popularity'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb47a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Vote_Average\n",
    "\n",
    "# ~8% missing values\n",
    "# left-skewed (~ -2.79) → impute with median\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_vote_avg': 'Vote_Average'}, inplace=True)\n",
    "\n",
    "# replace 0s with NaN\n",
    "merged_df['Vote_Average'] = merged_df['Vote_Average'].replace(0, np.nan)\n",
    "\n",
    "# median imputation\n",
    "median_vote_average = merged_df['Vote_Average'].median(skipna=True)\n",
    "merged_df['Vote_Average'] = merged_df['Vote_Average'].fillna(median_vote_average)\n",
    "\n",
    "# inspect range\n",
    "print(f\"Minimum value: {merged_df['Vote_Average'].min()}\")\n",
    "print(f\"Maximum value: {merged_df['Vote_Average'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Vote_Count\n",
    "\n",
    "# ~8% missing values\n",
    "# right-skewed (~3.08) → impute with median\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_vote_count': 'Vote_Count'}, inplace=True)\n",
    "\n",
    "# replace 0s with NaN\n",
    "merged_df['Vote_Count'] = merged_df['Vote_Count'].replace(0, np.nan)\n",
    "\n",
    "# median imputation\n",
    "median_vote_count = merged_df['Vote_Count'].median(skipna=True)\n",
    "merged_df['Vote_Count'] = merged_df['Vote_Count'].fillna(median_vote_count)\n",
    "\n",
    "# inspect range\n",
    "print(f\"Minimum value: {merged_df['Vote_Count'].min()}\")\n",
    "print(f\"Maximum value: {merged_df['Vote_Count'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b706102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Review_ID\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'review_id': 'Review_ID'}, inplace=True)\n",
    "# convert to string data type\n",
    "merged_df['Review_ID'] = merged_df['Review_ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28007d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Critic_ID\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'critic_id': 'Critic_ID'}, inplace=True)\n",
    "# convert to string data type\n",
    "merged_df['Critic_ID'] = merged_df['Critic_ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b69997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Created_Date\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'created_date': 'Created_Date'}, inplace=True)\n",
    "\n",
    "# convert from numeric to date format\n",
    "def convert_to_date(date_str):\n",
    "    if date_str != '':\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format='%Y%m%d').date().strftime('%m/%d/%Y')\n",
    "        except ValueError:\n",
    "            return 'Not available'\n",
    "    else:\n",
    "        return 'Not available'\n",
    "\n",
    "# apply function\n",
    "merged_df['Created_Date'] = merged_df['Created_Date'].apply(convert_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92eea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering – Published_Date\n",
    "\n",
    "# rename column\n",
    "merged_df.rename(columns={'pub_date': 'Published_Date'}, inplace=True)\n",
    "\n",
    "# apply convert date function to convert from numeric to date format\n",
    "merged_df['Published_Date'] = merged_df['Published_Date'].apply(convert_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a05faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENT\n",
    "# rename column\n",
    "merged_df.rename(columns={'content': 'Content'}, inplace=True)\n",
    "\n",
    "# impute NAs with Not available\n",
    "merged_df['Content'] = merged_df['Content'].fillna('Not available')\n",
    "merged_df['Content'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ecbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUBLISHER\n",
    "# rename column\n",
    "merged_df.rename(columns={'publisher': 'Publisher'}, inplace=True)\n",
    "merged_df['Publisher'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb84ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEWER RATING ROTTEN\n",
    "# drop column because all values are TRUE\n",
    "merged_df.drop('reviewer_rating_rotten', axis=1, inplace=True)\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'reviewer_rating_actual': 'Reviewer_Rating_Actual'})\n",
    "\n",
    "# convert letter grades to standardized score. the code creates a function called convert_grade that takes a letter grade \n",
    "#   and converts it into a standardized score between -1 and 1. The function checks if the input is a string. If it matches one \n",
    "#   of the valid letter grades, it returns the corresponding score. \n",
    "def convert_grade(grade):\n",
    "    if isinstance(grade, str):\n",
    "        if grade in ['F', 'D-', 'D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+']:\n",
    "            return (['F', 'D-', 'D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'].index(grade) - 6) / 5\n",
    "    return grade\n",
    "# apply the new convert_grade function to the column. \n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].apply(convert_grade)\n",
    "\n",
    "#after imputing these cases to the right letters, we will convert everything to standard\n",
    "#finding the number of cases that the score was a \"A minus\" etc. \n",
    "non_numeric_counts = merged_df['Reviewer_Rating_Actual'].str.extractall(r'(\\D+)')[0].value_counts()\n",
    "print(non_numeric_counts)\n",
    "\n",
    "#these are the scores that have 5 or more cases\n",
    "#going to impute them to letter score\n",
    "    #B-plus          51\n",
    "    #B-minus         41\n",
    "    #C-plus          32\n",
    "    #A-minus         15\n",
    "    #B               12 - spacing issue i believe\n",
    "    #A minus         10\n",
    "    #C-minus          8\n",
    "    #B plus           6\n",
    "    #B +              5\n",
    "    #C                5 \n",
    "\n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].replace(to_replace=['B-plus', 'B plus', 'B +'], value='B+')\n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].replace(to_replace=['B-minus', 'C-plus', 'A-minus', 'B ', 'A minus', 'C-minus', 'C ']\n",
    "                                                                                  , value=['B-', 'C+', 'A-', 'B', 'A-', 'C-','C'])\n",
    "\n",
    "# convert scales to standardized score: The code below creates another function called convert_scale.the scores like 4/5 and 8/10 in the data \n",
    "#   and converts them to the standarized scale. The function checks if the input is a string and if it contains a '/'character, which indicates \n",
    "#   the string is actually a ratio. the function splits the string into two parts, converts each part to a float, and then gets the ratio of those floats. \n",
    "#   the ratio is converted to a standardized score between -1 and 1 \n",
    "def convert_scale(score):\n",
    "    if type(score) == str and '/' in score:\n",
    "        parts = score.split('/')\n",
    "        if len(parts) == 2:\n",
    "            num = float(parts[0])\n",
    "            denom = float(parts[1])\n",
    "            if denom != 0:\n",
    "                return (num / denom) * 2 - 1\n",
    "    return score\n",
    "# the convert_score function is applied to the actual variable. \n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].apply(convert_scale)\n",
    "merged_df.head()\n",
    "\n",
    "# convert dates to standardized score: the code below creates a function that can deal with the cell values that \n",
    "#  are recognized as dates. if the cell is a string and has two '/' then it's split into two parts. Its calculated as a ratio, and then standarized. \n",
    "# If the denominator is a 0, it returns Not available. \n",
    "def convert_date_score(score):\n",
    "    if isinstance(score, str) and score.count('/') > 1:\n",
    "        score = score.split('/', maxsplit=2)[:2] # keep only first two elements\n",
    "        numerator, denominator = map(float, score)\n",
    "        if denominator != 0:\n",
    "            score = (numerator/denominator)*2-1\n",
    "        else:\n",
    "            score = 'Not available'\n",
    "    return score\n",
    "# apply the function to the dates in the variable. \n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].apply(convert_date_score)\n",
    "merged_df\n",
    "\n",
    "# rename to Reviewer_Rating\n",
    "merged_df = merged_df.rename(columns={'Reviewer_Rating_Actual': 'Reviewer_Rating'})\n",
    "# drop reviewer rating column becuase it is empty\n",
    "merged_df.drop('reviewer rating', axis=1, inplace=True)\n",
    "# coerce non numeric values that are left into NAs\n",
    "merged_df['Reviewer_Rating'] = pd.to_numeric(merged_df['Reviewer_Rating'], errors='coerce')\n",
    "# get rid of any values outside of -1 to 1 range\n",
    "merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].astype(float)\n",
    "merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].mask(~merged_df['Reviewer_Rating'].between(-1, 1), np.nan)\n",
    "merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].round(3)\n",
    "merged_df['Reviewer_Rating'].isna().sum()\n",
    "#left with about 36,000 NAs\n",
    "\n",
    "#the code below is for imputing NAs with the median. Hold off until phase 2, as missing reviewer data will be replaced with sentimate scores. \n",
    "# calculate the skew\n",
    "#reviewer_rating_skew = skew(merged_df['Reviewer_Rating'].dropna())\n",
    "#print(reviewer_rating_skew)\n",
    "# skew is -0.54 so use median score to impute NAs\n",
    "#median_reviewer_rating = merged_df['Reviewer_Rating'].median(skipna=True)\n",
    "#merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].fillna(median_reviewer_rating)\n",
    "# round column to 2 decimals\n",
    "#merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].round(2)\n",
    "#merged_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEW SRC URL, REVIEW OBJECT TYPE, REVIEW OBJECT HREF\n",
    "# drop these columns because they do not provide value\n",
    "merged_df.drop(['review_src_url', 'review_object_type', 'review_object_href'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUBLICATION\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'publication': 'Publication'})\n",
    "# convert to string data type\n",
    "merged_df['Publication'] = merged_df['Publication'].astype(str)\n",
    "merged_df['Publication'].head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc369f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEW OBJECT YEAR\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'review_object_year': 'Review_Object_Year'})\n",
    "# convert to string data type\n",
    "merged_df['Review_Object_Year'] = merged_df['Review_Object_Year'].astype(str)\n",
    "merged_df['Review_Object_Year'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITIC NAME\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'critic_name': 'Critic_Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI\n",
    "# create column to describe net profit as percentage\n",
    "merged_df['ROI'] = ((merged_df['Revenue'] - merged_df['Budget']) / merged_df['Budget']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa1b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONTH\n",
    "# create a new column for the month name\n",
    "merged_df['Month'] = merged_df['Release_Date'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first row showing percentage NAs\n",
    "merged_df = merged_df.drop(merged_df.index[0])\n",
    "\n",
    "# write the cleaned dataframe to a new CSV file\n",
    "merged_df.to_csv('merged_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
