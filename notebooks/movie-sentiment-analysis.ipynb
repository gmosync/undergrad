{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie Review Sentiment Analyzer\n",
    "\n",
    "# This notebook demonstrates a sentiment analysis pipeline on a dataset of movie reviews.\n",
    "# We apply natural language processing (NLP) techniques to classify reviews as positive or negative.\n",
    "\n",
    "# **Key steps:**\n",
    "# - Load and explore the dataset\n",
    "# - Text preprocessing and feature extraction\n",
    "# - Sentiment scoring with VADER\n",
    "# - Model building and evaluation\n",
    "\n",
    "# Libraries used include: `pandas`, `scikit-learn`, `NLTK`, `matplotlib`, `statsmodels`, and more.\n",
    "\n",
    "# > Note: This notebook was originally created as part of my undergraduate coursework. The code and results are from an academic project and demonstrate foundational sentiment analysis techniques using classical tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Statistical analysis\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ML preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('merged_file.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a0504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN CSV FILES AND MERGE\n",
    "movie_info = pd.read_csv('movie_info.csv')\n",
    "critic_reviews = pd.read_csv('CriticReviews_2018-2020.csv')\n",
    "# Merge the two dataframes on the 'review_object_title' column\n",
    "merged_df = pd.merge(movie_info, critic_reviews, on='review_object_title', how='outer', suffixes=('_movie', '_review'))\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee05f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME MovieID and MovieTitle\n",
    "merged_df = merged_df.rename(columns={'Unnamed: 0': 'Movie_ID', 'review_object_title': 'Movie_Title'})\n",
    "\n",
    "# MOVIE ID\n",
    "# Reset the MovieID column to start at 1 for each unique MovieTitle\n",
    "merged_df['Movie_ID'] = merged_df.groupby('Movie_Title').ngroup() + 1\n",
    "#merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column indicating how much of a row is missing\n",
    "# Create a boolean mask indicating which cells contain Not available, NaN, or the string 'Not available'\n",
    "na_mask = merged_df.isna() | merged_df.isin(['Not available'])\n",
    "\n",
    "# Count the number of cells in each row that contain Not available, NaN, or 'Not available'\n",
    "na_counts = na_mask.sum(axis=1)\n",
    "\n",
    "# Calculate the percentage of cells in each row that contain Not available, NaN, or 'Not available'\n",
    "na_percent = na_counts / len(merged_df.columns) * 100\n",
    "\n",
    "# Add the new column to the DataFrame\n",
    "merged_df['NA_Percent'] = na_percent\n",
    "#merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d28abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by NA_Percent in descending order\n",
    "merged_df.sort_values('NA_Percent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that have more than 50% Na values. These rows don't have enough information to use useful in a sentiment analysis. \n",
    "#Also, Not available of these columns contain the important review or reviewer rating necessary for the analysis. \n",
    "merged_df = merged_df[merged_df['NA_Percent'] <= 50]\n",
    "merged_df\n",
    "#319 rows have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the NA_Percent column\n",
    "merged_df = merged_df.drop('NA_Percent', axis=1)\n",
    "#merged_df\n",
    "\n",
    "# CHECK FOR NAs in columns \n",
    "# Calculate the percentage of NaN values for each column\n",
    "col_na_percentage = merged_df.isna().sum() / merged_df.shape[0] * 100\n",
    "# Add a new row at the top of the DataFrame with the column NaN percentages\n",
    "merged_df.loc[-1] = col_na_percentage.round(2)\n",
    "merged_df.index = merged_df.index + 1\n",
    "merged_df = merged_df.sort_index()\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e56fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the NA_Percent column\n",
    "merged_df = merged_df.drop('NA_Percent', axis=1)\n",
    "#merged_df\n",
    "\n",
    "# CHECK FOR NAs in columns \n",
    "# Calculate the percentage of NaN values for each column\n",
    "col_na_percentage = merged_df.isna().sum() / merged_df.shape[0] * 100\n",
    "# Add a new row at the top of the DataFrame with the column NaN percentages\n",
    "merged_df.loc[-1] = col_na_percentage.round(2)\n",
    "merged_df.index = merged_df.index + 1\n",
    "merged_df = merged_df.sort_index()\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUDGET\n",
    "# 8.12% NA\n",
    "# drop duplicate column\n",
    "merged_df.drop('tmdb_budget', axis=1, inplace=True)\n",
    "# rename column\n",
    "merged_df.rename(columns={'budget': 'Budget'}, inplace=True)\n",
    "# calculate the skew of the 'Budget' column\n",
    "Var_skew = skew(merged_df['Budget'].dropna())\n",
    "Var_skew\n",
    "# skew is 2.72 so use median to impute NA's or 0's\n",
    "merged_df['Budget'] = merged_df['Budget'].replace(0, np.nan)\n",
    "median_budget = merged_df['Budget'].median(skipna=True)\n",
    "merged_df['Budget'] = merged_df['Budget'].fillna(median_budget)\n",
    "merged_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNTIME\n",
    "# 8.24% NA\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'runtime': 'Runtime'})\n",
    "# calculate the skew of the 'Runtime' column\n",
    "Var_skew = skew(merged_df['Runtime'].dropna())\n",
    "Var_skew\n",
    "# skew is 3.46 so use median to impute NA's or 0's\n",
    "merged_df['Runtime'] = merged_df['Runtime'].replace(0, np.nan)\n",
    "median_runtime = merged_df['Runtime'].median(skipna=True)\n",
    "merged_df['Runtime'] = merged_df['Runtime'].fillna(median_runtime)\n",
    "merged_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL LANGUAGE\n",
    "# 8.12% NA\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'original_language': 'Original_Language'})\n",
    "# impute NAs with Not available\n",
    "merged_df['Original_Language'].fillna(value='Not available', inplace=True)\n",
    "# rename abbreviated values with full language name\n",
    "language_map = {\n",
    "    'Not available': 'Not available',\n",
    "    'en': 'English',\n",
    "    'zh': 'Chinese',\n",
    "    'sv': 'Swedish',\n",
    "    'es': 'Spanish',\n",
    "    'de': 'German',\n",
    "    'fr': 'French',\n",
    "    'xx': 'Not available',\n",
    "    'it': 'Italian',\n",
    "    'ka': 'Georgian',\n",
    "    'cs': 'Czech',\n",
    "    'fa': 'Persian',\n",
    "    'ro': 'Romanian',\n",
    "    'ja': 'Japanese',\n",
    "    'ar': 'Arabic',\n",
    "    'id': 'Indonesian',\n",
    "    'hu': 'Hungarian',\n",
    "    'tl': 'Tagalog',\n",
    "    'pl': 'Polish',\n",
    "    'sw': 'Swahili',\n",
    "    'no': 'Norwegian',\n",
    "    'pt': 'Portuguese',\n",
    "    'he': 'Hebrew',\n",
    "    'vi': 'Vietnamese',\n",
    "    'hi': 'Hindi',\n",
    "    'ru': 'Russian',\n",
    "    'af': 'Afrikaans',\n",
    "    'cn': 'Not available',\n",
    "    'ko': 'Korean',\n",
    "    'tr': 'Turkish',\n",
    "    'az': 'Azerbaijani',\n",
    "    'uk': 'Ukrainian',\n",
    "    'ga': 'Irish',\n",
    "    'as': 'Assamese',\n",
    "    'lv': 'Latvian',\n",
    "    'th': 'Thai',\n",
    "    'el': 'Greek',\n",
    "    'da': 'Danish',\n",
    "    'nl': 'Dutch',\n",
    "    'st': 'Southern Sotho',\n",
    "    'ky': 'Kyrgyz',\n",
    "    'fi': 'Finnish',\n",
    "    'is': 'Icelandic',\n",
    "    'ak': 'Akan',\n",
    "    'bn': 'Bengali',\n",
    "    'ml': 'Malayalam',\n",
    "    'hy': 'Armenian',\n",
    "    'am': 'Amharic',\n",
    "    'dz': 'Dzongkha',\n",
    "    'si': 'Sinhala',\n",
    "    'ln': 'Lingala',\n",
    "    'ur': 'Urdu',\n",
    "    'mn': 'Mongolian',\n",
    "    'la': 'Latin',\n",
    "    'te': 'Telugu',\n",
    "    'bs': 'Bosnian',\n",
    "    'bg': 'Bulgarian',\n",
    "    'ca': 'Catalan',\n",
    "    'kk': 'Kazakh',\n",
    "    'ne': 'Nepali',\n",
    "    'lt': 'Lithuanian',\n",
    "    'ta': 'Tamil',\n",
    "    'ms': 'Malay',\n",
    "    'wo': 'Wolof',\n",
    "    'eu': 'Basque',\n",
    "    'pa': 'Punjabi',\n",
    "    'mr': 'Marathi',\n",
    "    'hr': 'Croatian',\n",
    "    'mk': 'Macedonian',\n",
    "    'sq': 'Albanian',\n",
    "    'sr': 'Serbian'\n",
    "}\n",
    "\n",
    "merged_df['Original_Language'] = merged_df['Original_Language'].map(language_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVENUE\n",
    "# 8.12% NA\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_revenue': 'Revenue'}, inplace=True)\n",
    "# calculate the skew of the 'Revenue' column\n",
    "Var_skew = skew(merged_df['Revenue'].dropna())\n",
    "Var_skew\n",
    "# skew is 4.83 so use median to impute NA's or 0's\n",
    "merged_df['Revenue'] = merged_df['Revenue'].replace(0, np.nan)\n",
    "median_revenue = merged_df['Revenue'].median(skipna=True)\n",
    "merged_df['Revenue'] = merged_df['Revenue'].fillna(median_revenue)\n",
    "merged_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELEASE DATE\n",
    "# 8.36% NA\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'release_date': 'Release_Date'})\n",
    "# impute NAs with Not available\n",
    "merged_df['Release_Date'].fillna(value='Not available', inplace=True)\n",
    "merged_df['Release_Date'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd13cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULARITY\n",
    "# 8.12% NA\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_popularity': 'Popularity'}, inplace=True)\n",
    "# calculate the skew of the 'Popularity' column\n",
    "Var_skew = skew(merged_df['Popularity'].dropna())\n",
    "print(Var_skew)\n",
    "# skew is 17 so use median to impute NA's or 0's\n",
    "merged_df['Popularity'] = merged_df['Popularity'].replace(0, np.nan)\n",
    "median_popularity = merged_df['Popularity'].median(skipna=True)\n",
    "merged_df['Popularity'] = merged_df['Popularity'].fillna(median_popularity)\n",
    "merged_df['Popularity'].head(100)\n",
    "print(f\"Minimum value: {merged_df['Popularity'].min()}\")\n",
    "print(f\"Maximum value: {merged_df['Popularity'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTE AVGERAGE\n",
    "# 8.12% NA\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_vote_avg': 'Vote_Average'}, inplace=True)\n",
    "# calculate the skew of the 'Vote_Average' column\n",
    "Var_skew = skew(merged_df['Vote_Average'].dropna())\n",
    "print(Var_skew)\n",
    "# skew is -2.79 so use median to impute NA's or 0's\n",
    "merged_df['Vote_Average'] = merged_df['Vote_Average'].replace(0, np.nan)\n",
    "median_vote_average = merged_df['Vote_Average'].median(skipna=True)\n",
    "merged_df['Vote_Average'] = merged_df['Vote_Average'].fillna(median_vote_average)\n",
    "merged_df['Vote_Average'].head(100)\n",
    "print(f\"Minimum value: {merged_df['Vote_Average'].min()}\")\n",
    "print(f\"Maximum value: {merged_df['Vote_Average'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedae362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTE COUNT\n",
    "# 8.12% NA\n",
    "# rename column\n",
    "merged_df.rename(columns={'tmdb_vote_count': 'Vote_Count'}, inplace=True)\n",
    "# calculate the skew of the 'Vote_Count' column\n",
    "Var_skew = skew(merged_df['Vote_Count'].dropna())\n",
    "print(Var_skew)\n",
    "# skew is 3.08 so use median to impute NA's or 0's\n",
    "merged_df['Vote_Count'] = merged_df['Vote_Count'].replace(0, np.nan)\n",
    "median_vote_count = merged_df['Vote_Count'].median(skipna=True)\n",
    "merged_df['Vote_Count'] = merged_df['Vote_Count'].fillna(median_vote_count)\n",
    "merged_df['Vote_Count'].head(100)\n",
    "print(f\"Minimum value: {merged_df['Vote_Count'].min()}\")\n",
    "print(f\"Maximum value: {merged_df['Vote_Count'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMDBID and INDEX\n",
    "# drop columns because we made our own index called MovieID\n",
    "merged_df.drop(['tmdbid', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEW ID\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'review_id': 'Review_ID'})\n",
    "# convert to string data type\n",
    "merged_df['Review_ID'] = merged_df['Review_ID'].astype(str)\n",
    "merged_df['Review_ID'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITIC ID\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'critic_id': 'Critic_ID'})\n",
    "# convert to string data type\n",
    "merged_df['Critic_ID'] = merged_df['Critic_ID'].astype(str)\n",
    "merged_df['Critic_ID'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46390c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATED DATE\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'created_date': 'Created_Date'})\n",
    "# convert from numeric to date time format\n",
    "def convert_to_date(date_str):\n",
    "    if date_str != '':\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format='%Y%m%d').date().strftime('%m/%d/%Y')\n",
    "        except ValueError:\n",
    "            return 'Not available'\n",
    "    else:\n",
    "        return 'Not available'\n",
    "# apply function\n",
    "merged_df['Created_Date'] = merged_df['Created_Date'].apply(convert_to_date)\n",
    "merged_df['Created_Date'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUBLISHED DATE\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'pub_date': 'Published_Date'})\n",
    "# apply convert date function to convert from numeric to date time format\n",
    "merged_df['Published_Date'] = merged_df['Published_Date'].apply(convert_to_date)\n",
    "merged_df['Published_Date'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b388673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENT\n",
    "# 0.01% NA\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'content': 'Content'})\n",
    "# impute NAs with Not available\n",
    "merged_df['Content'].fillna(value='Not available', inplace=True)\n",
    "# drop rows with NAs\n",
    "# merged_df = merged_df.dropna(subset=['Content'])\n",
    "merged_df['Content'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312195f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUBLISHER\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'publisher': 'Publisher'})\n",
    "merged_df['Publisher'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEWER RATING ROTTEN\n",
    "# 0 NAs\n",
    "# drop because it only has values TRUE\n",
    "merged_df.drop('reviewer_rating_rotten', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c346492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'reviewer_rating_actual': 'Reviewer_Rating_Actual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert letter grades to standardized score. the code creates a function called convert_grade that takes a letter grade \n",
    "#   and converts it into a standardized score between -1 and 1. The function checks if the input is a string. If it matches one \n",
    "#   of the valid letter grades, it returns the corresponding score. \n",
    "def convert_grade(grade):\n",
    "    if isinstance(grade, str):\n",
    "        if grade in ['F', 'D-', 'D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+']:\n",
    "            return (['F', 'D-', 'D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'].index(grade) - 6) / 5\n",
    "    return grade\n",
    "# apply the new convert_grade function to the column. \n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].apply(convert_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9660abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after imputing these cases to the right letters, we will convert everything to standard\n",
    "#finding the number of cases that the score was a \"A minus\" etc. \n",
    "non_numeric_counts = merged_df['Reviewer_Rating_Actual'].str.extractall('(\\D+)')[0].value_counts()\n",
    "print(non_numeric_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the scores that have 5 or more cases\n",
    "#going to impute them to letter score\n",
    "    #B-plus          51\n",
    "    #B-minus         41\n",
    "    #C-plus          32\n",
    "    #A-minus         15\n",
    "    #B               12 - spacing issue i believe\n",
    "    #A minus         10\n",
    "    #C-minus          8\n",
    "    #B plus           6\n",
    "    #B +              5\n",
    "    #C                5 \n",
    "\n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].replace(to_replace=['B-plus', 'B plus', 'B +'], value='B+')\n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].replace(to_replace=['B-minus', 'C-plus', 'A-minus', 'B ', 'A minus', 'C-minus', 'C ']\n",
    "                                                                                  , value=['B-', 'C+', 'A-', 'B', 'A-', 'C-','C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b44b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert scales to standardized score: The code below creates another function called convert_scale.the scores like 4/5 and 8/10 in the data \n",
    "#   and converts them to the standarized scale. The function checks if the input is a string and if it contains a '/'character, which indicates \n",
    "#   the string is actually a ratio. the function splits the string into two parts, converts each part to a float, and then gets the ratio of those floats. \n",
    "#   the ratio is converted to a standardized score between -1 and 1 \n",
    "def convert_scale(score):\n",
    "    if type(score) == str and '/' in score:\n",
    "        parts = score.split('/')\n",
    "        if len(parts) == 2:\n",
    "            num = float(parts[0])\n",
    "            denom = float(parts[1])\n",
    "            if denom != 0:\n",
    "                return (num / denom) * 2 - 1\n",
    "    return score\n",
    "# the convert_score function is applied to the actual variable. \n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].apply(convert_scale)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78baaee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to standardized score: the code below creates a function that can deal with the cell values that \n",
    "#  are recognized as dates. if the cell is a string and has two '/' then it's split into two parts. Its calculated as a ratio, and then standarized. \n",
    "# If the denominator is a 0, it returns Not available. \n",
    "def convert_date_score(score):\n",
    "    if isinstance(score, str) and score.count('/') > 1:\n",
    "        score = score.split('/', maxsplit=2)[:2] # keep only first two elements\n",
    "        numerator, denominator = map(float, score)\n",
    "        if denominator != 0:\n",
    "            score = (numerator/denominator)*2-1\n",
    "        else:\n",
    "            score = 'Not available'\n",
    "    return score\n",
    "# apply the function to the dates in the variable. \n",
    "merged_df['Reviewer_Rating_Actual'] = merged_df['Reviewer_Rating_Actual'].apply(convert_date_score)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba64dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to Reviewer_Rating\n",
    "merged_df = merged_df.rename(columns={'Reviewer_Rating_Actual': 'Reviewer_Rating'})\n",
    "# drop reviewer rating column becuase it is empty\n",
    "merged_df.drop('reviewer rating', axis=1, inplace=True)\n",
    "# coerce non numeric values that are left into NAs\n",
    "merged_df['Reviewer_Rating'] = pd.to_numeric(merged_df['Reviewer_Rating'], errors='coerce')\n",
    "# get rid of any values outside of -1 to 1 range\n",
    "merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].astype(float)\n",
    "merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].mask(~merged_df['Reviewer_Rating'].between(-1, 1), np.nan)\n",
    "merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].round(3)\n",
    "merged_df['Reviewer_Rating'].isna().sum()\n",
    "#left with about 36,000 NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code below is for imputing NAs with the median. Hold off until phase 2, as missing reviewer data will be replaced with sentimate scores. \n",
    "# calculate the skew\n",
    "#reviewer_rating_skew = skew(merged_df['Reviewer_Rating'].dropna())\n",
    "#print(reviewer_rating_skew)\n",
    "# skew is -0.54 so use median score to impute NAs\n",
    "#median_reviewer_rating = merged_df['Reviewer_Rating'].median(skipna=True)\n",
    "#merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].fillna(median_reviewer_rating)\n",
    "# round column to 2 decimals\n",
    "#merged_df['Reviewer_Rating'] = merged_df['Reviewer_Rating'].round(2)\n",
    "#merged_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMETER\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'tmeter': 'Tomato_Meter'})\n",
    "# calculate the skew of the 'Tomato_Meter' column\n",
    "tmeter_skew = skew(merged_df['Tomato_Meter'].dropna())\n",
    "print(tmeter_skew)\n",
    "# skew is -2.7 so use median to impute NA's\n",
    "merged_df['Tomato_Meter'] = merged_df['Tomato_Meter'].replace(0, np.nan)\n",
    "median_tomato_meter = merged_df['Tomato_Meter'].median(skipna=True)\n",
    "merged_df['Tomato_Meter'] = merged_df['Tomato_Meter'].fillna(median_tomato_meter)\n",
    "merged_df['Tomato_Meter'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f92cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEW SRC URL and REVIEW OBJECT TYPE and REVIEW OBJECT HREF\n",
    "# 0 NA for all three\n",
    "# drop these columns because they do not provide value\n",
    "merged_df = merged_df.drop(['review_src_url', 'review_object_type', 'review_object_href'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491dc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUBLICATION\n",
    "# 0 NA\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'publication': 'Publication'})\n",
    "# convert to string data type\n",
    "merged_df['Publication'] = merged_df['Publication'].astype(str)\n",
    "merged_df['Publication'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEW OBJECT YEAR\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'review_object_year': 'Review_Object_Year'})\n",
    "# convert to string data type\n",
    "merged_df['Review_Object_Year'] = merged_df['Review_Object_Year'].astype(str)\n",
    "merged_df['Review_Object_Year'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITIC NAME\n",
    "# 0 NAs\n",
    "# rename column\n",
    "merged_df = merged_df.rename(columns={'critic_name': 'Critic_Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI\n",
    "# create column to describe net profit as percentage\n",
    "# ROI = ((Revenue - Budget) / Budget) * 100\n",
    "\n",
    "merged_df['ROI'] = ((merged_df['Revenue'] - merged_df['Budget']) / merged_df['Budget']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONTH\n",
    "\n",
    "# create a column to describe the month of movie release\n",
    "merged_df['Release_Date'] = pd.to_datetime(merged_df['Release_Date'], errors='coerce')\n",
    "# create a new column for the month name\n",
    "merged_df['Month'] = merged_df['Release_Date'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first row showing percentage NAs\n",
    "merged_df = merged_df.drop(merged_df.index[0])\n",
    "\n",
    "# WRITING THE DATAFRAME TO A NEW CSV FILE\n",
    "merged_df.to_csv('merged_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ebdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF PART 1\n",
    "# START OF PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d466bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the 'Revenue' column\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.hist(df['Revenue'], bins=20, edgecolor='black')\n",
    "\n",
    "# Customize x-axis labels\n",
    "ax.set_xlabel('Revenue (in billions)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x/1e9:g}'))\n",
    "ax.set_xlim(0, 3e9)\n",
    "\n",
    "plt.title('Histogram of Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue'].plot(kind='box')\n",
    "plt.ylabel('Revenue (in millions)')\n",
    "plt.title('Boxplot of Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc787e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Budget']\n",
    "y = df['Revenue']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Revenue vs. Budget')\n",
    "plt.xlabel('Budget (in billions)')\n",
    "plt.ylabel('Revenue (in billions)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5278f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute \n",
    "median_runtime = df['Runtime'].median()\n",
    "df.loc[df['Runtime'] == 0, 'Runtime'] = median_runtime\n",
    "df.loc[df['Runtime'] > 200, 'Runtime'] = median_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f1a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Runtime']\n",
    "y = df['Revenue']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Revenue vs. Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Revenue in Billions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a500f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Vote_Average']\n",
    "y = df['Revenue']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Revenue vs. Vote_Average')\n",
    "plt.xlabel('Vote_Average')\n",
    "plt.ylabel('Revenue in Billions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Vote_Count']\n",
    "y = df['Revenue']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Revenue vs. Vote_Count')\n",
    "plt.xlabel('Vote_Count')\n",
    "plt.ylabel('Revenue in Billions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce02d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_revenue = df.groupby('Month')['Revenue'].mean()\n",
    "\n",
    "# Create a new DataFrame with the monthly labels and average revenues\n",
    "monthlyrevenue = pd.DataFrame({\n",
    "    'Month': monthly_revenue.index,\n",
    "    'Average Revenue': monthly_revenue.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define default blue color instead of the green color map\n",
    "colors = 'C0'  # 'C0' is the default blue color in Matplotlib\n",
    "\n",
    "# Create an ordered categorical data type for the 'Month' column\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "               'August', 'September', 'October', 'November', 'December']\n",
    "cat_dtype = pd.api.types.CategoricalDtype(categories=month_order, ordered=True)\n",
    "monthlyrevenue['Month'] = monthlyrevenue['Month'].astype(cat_dtype)\n",
    "\n",
    "# Sort the dataframe by the 'Month' column\n",
    "monthlyrevenue = monthlyrevenue.sort_values('Month')\n",
    "\n",
    "# Create a bar plot with monthly revenue and color the bars by revenue\n",
    "plt.bar(monthlyrevenue['Month'], monthlyrevenue['Average Revenue'], color=colors)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Revenue ($)')\n",
    "plt.title('Average Revenue by Month')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis tick labels\n",
    "tick_labels = ['${:,.0f}'.format(x) for x in plt.yticks()[0]]\n",
    "plt.yticks(plt.yticks()[0], tick_labels)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_revenue = df.groupby('Genre_1')['Revenue'].mean().reset_index()\n",
    "\n",
    "# Create a bar plot with genre_1 and revenue\n",
    "plt.bar(genre_revenue['Genre_1'], genre_revenue['Revenue'])\n",
    "# Customize the plot\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Average Revenue (in Hundred Millions)')\n",
    "plt.title('Average Revenue by Genre')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Vote_Average'], bins=20)\n",
    "plt.title('Distribution of Vote Average')\n",
    "plt.xlabel('Vote Average')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Vote_Average'].plot(kind='density')\n",
    "plt.title('Distribution of Vote Average')\n",
    "plt.xlabel('Vote Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7827d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Runtime']\n",
    "y = df['Vote_Average']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Vote Average vs. Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Vote Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Vote_Average']\n",
    "y = df['Revenue']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Revenue vs. Vote Average')\n",
    "plt.xlabel('Vote_Average')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6025c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Vote_Average']\n",
    "y = df['Vote_Count']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Vote Count vs. Vote Average')\n",
    "plt.xlabel('Vote Average')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Vote_Average']\n",
    "y = df['Reviewer_Rating']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Reviewer Rating vs. Vote Average')\n",
    "plt.xlabel('Vote Average')\n",
    "plt.ylabel('Reviewer Rating')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['Tomato_Meter'] >= 0]\n",
    "# create the scatter plot using the filtered dataframe\n",
    "x = df_filtered['Vote_Average']\n",
    "y = df_filtered['Tomato_Meter']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Tomato Meter vs. Vote Average')\n",
    "plt.xlabel('Tomato_Meter')\n",
    "plt.ylabel('Vote Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be749b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by month and calculate the mean of the 'Vote Average' column\n",
    "month_vote_avg = df.groupby('Month')['Vote_Average'].mean().reset_index()\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Create a bar chart of vote average by month\n",
    "plt.bar(month_vote_avg['Month'], month_vote_avg['Vote_Average'])\n",
    "# Add data labels to the bars\n",
    "for i, v in enumerate(month_vote_avg['Vote_Average']):\n",
    "    plt.text(i, v, '{:.2f}'.format(v), ha='center', va='bottom')\n",
    "# Customize the plot\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Vote Average')\n",
    "plt.title('Vote Average by Month')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by genre and calculate the mean of the 'Vote Average' column\n",
    "genre_vote_avg = df.groupby('Genre_1')['Vote_Average'].mean().reset_index()\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Create a bar chart of vote average by genre\n",
    "plt.bar(genre_vote_avg['Genre_1'], genre_vote_avg['Vote_Average'])\n",
    "\n",
    "# Add labels to the bars\n",
    "for i, v in enumerate(genre_vote_avg['Vote_Average']):\n",
    "    plt.text(i, v, '{:.2f}'.format(v), ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Vote Average')\n",
    "plt.title('Vote Average by Genre')\n",
    "plt.xticks(rotation=60)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a230bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Vote_Count'], bins=50)\n",
    "plt.title('Distribution of Vote Count')\n",
    "plt.xlabel('Vote Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Budget']\n",
    "y = df['Vote_Count']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Vote Count vs. Budget')\n",
    "plt.xlabel('Budget (in billions)')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e8deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Runtime']\n",
    "y = df['Vote_Count']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Vote Count vs. Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972809c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Revenue']\n",
    "y = df['Vote_Count']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Vote Count vs. Revenue')\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Vote_Average']\n",
    "y = df['Vote_Count']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Vote Count vs. Vote Average')\n",
    "plt.xlabel('Vote Average')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ec998",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Reviewer_Rating']\n",
    "y = df['Vote_Count']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title('Vote Count vs. Reviewer Rating')\n",
    "plt.xlabel('Reviewer Rating')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Month' column to a categorical data type\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "               'August', 'September', 'October', 'November', 'December']\n",
    "cat_dtype = pd.api.types.CategoricalDtype(categories=month_order, ordered=True)\n",
    "df['Month'] = df['Month'].astype(cat_dtype)\n",
    "\n",
    "# Group the data by month and calculate the sum of the 'Vote Count' column\n",
    "monthly_vote_count = df.groupby('Month')['Vote_Count'].sum().reset_index()\n",
    "\n",
    "# Create a bar chart of vote count by month\n",
    "plt.bar(monthly_vote_count['Month'], monthly_vote_count['Vote_Count'])\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.title('Vote Count by Month')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeeec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by genre and calculate the sum of the 'Vote Count' column\n",
    "genre_vote_count = df.groupby('Genre_1')['Vote_Count'].sum().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create a bar chart of vote count by genre\n",
    "plt.bar(genre_vote_count['Genre_1'], genre_vote_count['Vote_Count'])\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.title('Vote Count by Genre')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df[df['Release_Date'] != 'Not available']\n",
    "print(df_cleaned['Release_Date'].dtype)\n",
    "df_cleaned['Release_Month'] = pd.to_datetime(df_cleaned['Release_Date']).dt.month\n",
    "\n",
    "df_cleaned_rating = df_cleaned.dropna(subset=['Reviewer_Rating'])\n",
    "df_cleaned_month_rating = df_cleaned_rating.dropna(subset=['Release_Month'])\n",
    "\n",
    "# Group df_cleaned by month and get mean of Reviewer_Rating \n",
    "month_rating = df_cleaned_month_rating.groupby(['Release_Month'])['Reviewer_Rating'].mean()\n",
    "import calendar\n",
    "month_abbr = list(calendar.month_abbr)[1:] # Define a list of month abbreviations\n",
    "\n",
    "\n",
    "df_filtered = df_cleaned[df_cleaned['Reviewer_Rating'] > 0.6]\n",
    "count_by_month = df_filtered['Release_Month'].value_counts()\n",
    "count_by_month = count_by_month.sort_index()\n",
    "\n",
    "# Define month labels\n",
    "month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.bar(month_labels, count_by_month)\n",
    "plt.title('Count of Movies with Reviewer_Rating > 0.6 by Release Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# September is traditionally known as the start of the \"fall movie season,\" where studios release \n",
    "# prestige films in the lead up to award season. This is because many of the high-profile film festivals \n",
    "# (Venice Film Festival and the Toronto International Film Festival) take place in September. As a result, \n",
    "# studios may choose to release their films in September in order to coincide with these festivals and \n",
    "# generate buzz and positive reviews for their films. Additionally, the period from September to December \n",
    "# leads up to the award season, during which studios release their most highly regarded and critically \n",
    "# acclaimed films in the hopes of receiving nominations and awards. This background information could \n",
    "# explain the higher count of reviewer_ratings above .6 from September to December. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f41977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# compute the correlation matrix\n",
    "corr_matrix = numeric_cols.corr()\n",
    "\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of Revenue by Month\n",
    "df.groupby('Month')['Revenue'].sum().plot(kind='bar', title='Revenue by Month', figsize=(8, 6))\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e3419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the 'Budget' column\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Histogram of Budget')\n",
    "plt.xlabel('Budget (in billions)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(df['Budget'], bins=20, edgecolor='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5042b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the 'Runtime' column\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Histogram of Runtime')\n",
    "plt.xlabel('Runtime (in minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(df['Runtime'], bins=20, edgecolor='black')\n",
    "\n",
    "# Customize x-axis labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF PART 2\n",
    "# START OF PART 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a393f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment requirements:\n",
    "#1. Use either sentiment analyzer introduced in class to generate sentiment polarity scores for the content column in the dataframe.\n",
    "#2. Impute NAs in the reviewer rating columns with the sentiment polarity scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daadbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VADER ANALYSIS\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df.head() # The Content column contains the reviews that need to be analyzed.\n",
    "#Content is what we will complete a sentiment analysis on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the contents of the first review for an initial review \n",
    "text1 = df.iloc[0].Content\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24490050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the polarity scores on the 1st review to make sure the analyzer runs properly. \n",
    "analyzer.polarity_scores(text1) \n",
    "#{'neg': 0.0, 'neu': 0.873, 'pos': 0.127, 'compound': 0.4939}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code saves the absolute compound polarity scores in the column Polarity_Score and the sentiment label (positive or negative) in a column called Sentiment \n",
    "compounds=[]\n",
    "values=[]\n",
    "for index, row in df.iterrows():\n",
    "    text = row.Content\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compounds.append(scores['compound'])\n",
    "    if scores['compound']>0:\n",
    "        values.append('POSITIVE')\n",
    "    else:\n",
    "        values.append('NEGATIVE')\n",
    "\n",
    "df['Polarity_Score']=compounds\n",
    "df['Polarity_Score']=df['Polarity_Score'].round(3)\n",
    "df['Sentiment']=values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4cfef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66554f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAIR\n",
    "import flair\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "import pandas as pd\n",
    "df1= pd.read_csv('merged_file.csv').head(100)\n",
    "\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "sentence = Sentence('The food was mid.')\n",
    "classifier.predict(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flair values\n",
    "values2 = []\n",
    "scores=[]\n",
    "for index, row in df1.iterrows():\n",
    "    text = Sentence(row.Content)\n",
    "    classifier.predict(text)\n",
    "    values2.append(text.labels[0].to_dict()['value'])\n",
    "    scores.append(text.to_dict()['all labels'][0]['confidence'])\n",
    "\n",
    "df1['Sentiment'] = values2\n",
    "df1['Polarity'] = scores #Scores are absolute instead of [-1,1] from Vader\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c847a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Vader values are a little bit more accurate for the Content column versus the Flair style. \n",
    "#Example: \n",
    "#Row 4: The Platform is about as subtle as a punch in the face but that's by design. It's social commentary via blunt instrument using genre trappings and pitch-black satire as a club bashing at its targets with barely restrained glee.\n",
    "#Row 98: Crow and his two fine Welsh-burred leads commit fully to the anguished nerve-fraying cause but their efforts can't conceal a certain thinness to the dramatic material...\n",
    "#Row 100: Many audiences are going to be utterly shocked at the lengths the two leading actors Pattinson Dafoe are pushed. They have a loathsome dynamic. However those who can get on \n",
    "#  Eggers' level will be hypnotized by this eccentric experiment.\n",
    "\n",
    "#The flair analysis designates these ratings as negative, but after reading the rating itself, I would consider these as more positive than negative. \n",
    "#Thus, we will use Vader as the sentiment analysis reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute the NAs of Reviewer_Rating with the polarity score\n",
    "df['Reviewer_Rating'] = df['Reviewer_Rating'].fillna(df.pop('Polarity_Score'))\n",
    "#this code replaces the Reviewer_Rating with Polarity Score and deletes Polarity score column. Retain the sentiment column for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Written to CSV\n",
    "df.to_csv('merged_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF PART 3\n",
    "# START OF PART 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the original DataFrame\n",
    "df_copy = df.copy()\n",
    "\n",
    "# create dummy variables for Month and Genre columns\n",
    "dummy_month = pd.get_dummies(df_copy['Month'])\n",
    "dummy_genre = pd.get_dummies(df_copy['Genre_1'])\n",
    "\n",
    "# concatenate the dummy variables with the original DataFrame\n",
    "df_copy = pd.concat([df_copy, dummy_month, dummy_genre], axis=1)\n",
    "\n",
    "# remove the original Month and Genre columns\n",
    "df_copy = df_copy.drop(['Month', 'Genre_1', 'Genre_2', 'Genre_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove categorical columns\n",
    "df_copy = df_copy.select_dtypes(include='number')\n",
    "\n",
    "# drop rows with missing or infinite values\n",
    "df_copy = df_copy.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10330732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create independent variable matrix X and dependent variable vector y\n",
    "X = df_copy[['Runtime', 'Popularity', 'Vote_Count',\n",
    "       'Tomato_Meter', 'Reviewer_Rating', \n",
    "       'April', 'August', 'December', 'February', 'January', 'June',\n",
    "       'March', 'May', 'November', 'October', 'September', 'Action',\n",
    "       'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "       'Romance', 'Science Fiction', 'Thriller',\n",
    "       'War', 'Western']] \n",
    "# Remove TV movie bc its not statistically significant\n",
    "# Remove Drama bc it's correlation with Revenue is only -.15 AND it has a problematic VIF of 25.27\n",
    "# Remove July bc its correlation is only .03 and is not statistically significant\n",
    "# Budget had a correation of .79 but it has multicollinearity with vote_count. vote_count has a higher correlation at .82 so remove budget \n",
    "#remove vote_average bec of 33.3 multicollinearity \n",
    "y = df_copy['Revenue']\n",
    "# add constant term to X matrix\n",
    "X = sm.add_constant(X)\n",
    "# fit OLS model\n",
    "model1 = sm.OLS(y, X).fit()\n",
    "# print summary of model\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb38713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check vifs\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictor and dependent variables\n",
    "X = df_copy[['Popularity', 'Vote_Count',\n",
    "        'Tomato_Meter', 'Reviewer_Rating', \n",
    "        'April', 'August', 'December', 'February', 'January', 'June',\n",
    "        'March', 'May', 'November', 'October', 'September', 'Action',\n",
    "        'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary',\n",
    "        'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "        'Romance', 'Science Fiction', 'Thriller', 'War', 'Western']] \n",
    "\n",
    "y = df['Revenue']\n",
    "\n",
    "# Remove TV movie because it's not statistically significant\n",
    "# Remove Drama because its correlation with Revenue is only -.15 AND it has a problematic VIF of 25.27\n",
    "# Remove July because its correlation is only .03 and is not statistically significant\n",
    "# Remove Budget because it has multicollinearity with Vote_Count. Vote_Count has a higher correlation at .82, so remove Budget \n",
    "# Remove Runtime and Vote_Average due to multicollinearity \n",
    "\n",
    "# Standardize predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Add constant term to X matrix\n",
    "X_scaled = sm.add_constant(X_scaled)\n",
    "\n",
    "# Fit OLS model\n",
    "model = sm.OLS(y, X_scaled).fit()\n",
    "\n",
    "# Print summary of model results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17480a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check vifs\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create independent variable matrix X and dependent variable vector y\n",
    "X = df_copy[['Reviewer_Rating','Popularity', 'Budget',  'Vote_Count', 'Tomato_Meter',\n",
    "       'April', 'August', 'December', 'February', 'January', 'July', 'June',\n",
    "       'March', 'May', 'November', 'October', 'September', 'Adventure',\n",
    "       'Animation', 'Comedy', 'Crime', 'Documentary', 'Action', \n",
    "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "       'Romance', 'Science Fiction', 'TV Movie', 'Thriller',\n",
    "       'War', 'Western']]\n",
    "# Removed vote_average. vif of 40\n",
    "# Removed drama. vif of 37\n",
    "# Removed runtime. vif of 14\n",
    "\n",
    "y = df_copy['Revenue']\n",
    "\n",
    "# Standardize predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a new DataFrame with standardized X and original column names\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Forward stepwise regression function\n",
    "def forward_selection(X, y, threshold_in=0.01, verbose=True):\n",
    "    included = []\n",
    "    while True:\n",
    "        changed = False\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    model = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
    "    return model\n",
    "\n",
    "# Perform forward stepwise selection and print the model summary\n",
    "model = forward_selection(X_scaled_df, y)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check vifs \n",
    "vifs = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])],\n",
    "                 index=X.columns)\n",
    "print(\"VIFs:\")\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create independent variable matrix X and dependent variable vector y\n",
    "X = df_copy[['Budget', 'Runtime', 'Popularity', 'Revenue',\n",
    "       'Vote_Count', 'Reviewer_Rating',\n",
    "       'Tomato_Meter',\n",
    "       'April', 'August', 'December', 'February', 'January', 'July', 'June',\n",
    "       'March', 'May', 'November', 'October', 'September', 'Action',\n",
    "       'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "       'Romance', 'Science Fiction', 'TV Movie', 'Thriller',\n",
    "       'War', 'Western']]\n",
    "\n",
    "y = df_copy['Vote_Average']\n",
    "\n",
    "# add constant term to X matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# fit OLS model\n",
    "model2 = sm.OLS(y, X).fit()\n",
    "\n",
    "# print summary of model\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vifs = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])],\n",
    "                 index=X.columns)\n",
    "print(\"VIFs:\")\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf78e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aeb0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create independent variable matrix X and dependent variable vector y\n",
    "X = df_copy[[  'Popularity', 'Budget', 'Vote_Count',\n",
    "        'Reviewer_Rating', 'Tomato_Meter',\n",
    "       'April', 'August', 'December', 'February', 'January', 'July', 'June',\n",
    "       'March', 'May', 'November', 'October', 'September', 'Action',\n",
    "       'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', \n",
    "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "       'Romance', 'Science Fiction', 'TV Movie', 'Thriller',\n",
    "       'War', 'Western']]\n",
    "\n",
    "#remove drama, vif is 36\n",
    "#remove revenue to reduce vifs from 6 to under 5 for everything \n",
    "#runtime, vif 13\n",
    "\n",
    "y = df_copy['Vote_Average']\n",
    "\n",
    "# Standardize predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a new DataFrame with standardized X and original column names\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Forward stepwise regression function\n",
    "def forward_selection(X, y, threshold_in=0.01, verbose=True):\n",
    "    included = []\n",
    "    while True:\n",
    "        changed = False\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print('Add {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    model = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
    "    return model\n",
    "\n",
    "# Perform forward stepwise selection and print the model summary\n",
    "model = forward_selection(X_scaled_df, y)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81906a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check vifs\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vifs = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])],\n",
    "                 index=X.columns)\n",
    "print(\"VIFs:\")\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create independent variable matrix X and dependent variable vector y\n",
    "X = df_copy[['Budget', 'Runtime', 'Popularity', 'Revenue',\n",
    "       'Vote_Average', 'Reviewer_Rating', 'Tomato_Meter',\n",
    "       'April', 'August', 'December', 'February', 'January', 'July', 'June',\n",
    "       'March', 'May', 'November', 'October', 'September', 'Action',\n",
    "       'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "       'Romance', 'Science Fiction', 'TV Movie', 'Thriller',\n",
    "       'War', 'Western']]\n",
    "y = df_copy['Vote_Count']\n",
    "\n",
    "# add constant term to X matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# fit OLS model\n",
    "model3 = sm.OLS(y, X).fit()\n",
    "\n",
    "# print summary of model\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vifs = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])],\n",
    "                 index=X.columns)\n",
    "print(\"VIFs:\")\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create independent variable matrix X and dependent variable vector y\n",
    "X = df_copy[[ 'Popularity', 'Revenue',\n",
    "        'Reviewer_Rating', 'Tomato_Meter',\n",
    "       'April', 'August', 'December', 'February', 'January', 'July', 'June',\n",
    "       'March', 'May', 'November', 'October', 'September', 'Action',\n",
    "       'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', \n",
    "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "       'Romance', 'Science Fiction', 'TV Movie', 'Thriller',\n",
    "       'War', 'Western']]\n",
    "# remove vote_average, vif of 40\n",
    "# remove drama, vif of 36\n",
    "#remove budget, vif of 6\n",
    "#remove runtime, vif 13\n",
    "y = df_copy['Vote_Count']\n",
    "\n",
    "# Standardize predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a new DataFrame with standardized X and original column names\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Forward stepwise regression function\n",
    "def forward_selection(X, y, threshold_in=0.01, verbose=True):\n",
    "    included = []\n",
    "    while True:\n",
    "        changed = False\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print('Add {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    model = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
    "    return model\n",
    "\n",
    "# Perform forward stepwise selection and print the model summary\n",
    "model = forward_selection(X_scaled_df, y)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21483c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check vifs \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vifs = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])],\n",
    "                 index=X.columns)\n",
    "print(\"VIFs:\")\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1295d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of 'Vote_Count'\n",
    "mean_vote_count = df_copy['Vote_Count'].mean()\n",
    "std_vote_count = df_copy['Vote_Count'].std()\n",
    "\n",
    "# Display one standard deviation above and below the mean\n",
    "print(f'Mean Vote_Count: {mean_vote_count:.2f}')\n",
    "print(f'Standard Deviation of Vote_Count: {std_vote_count:.2f}')\n",
    "print(f'One Standard Deviation Above Mean Vote_Count: {mean_vote_count + std_vote_count:.2f}')\n",
    "print(f'One Standard Deviation Below Mean Vote_Count: {mean_vote_count - std_vote_count:.2f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
